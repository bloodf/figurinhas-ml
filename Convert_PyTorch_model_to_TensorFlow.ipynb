{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Convert PyTorch model to TensorFlow.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYYLVKHguJcp"
   },
   "source": [
    "# Open Nueral Network Exchange [ONNX]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0W503l0z3yhl"
   },
   "source": [
    "###Installing ONNX and other required libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHcTO5Jpk5Bv",
    "outputId": "2d14cd14-efc7-40e8-8981-ab6aab868031"
   },
   "source": [
    "!pip install onnx"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.7.4.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx) (54.0.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XltrK_M8xZAg",
    "outputId": "5052d02a-6d9a-458e-f3a3-2001b2e83c47"
   },
   "source": [
    "!pip install tensorflow-addons\n",
    "!git clone https://github.com/onnx/onnx-tensorflow.git && cd onnx-tensorflow && pip install -e ."
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.12.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
      "fatal: destination path 'onnx-tensorflow' already exists and is not an empty directory.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7V6MzGtIkxb5"
   },
   "source": [
    "### Restart Runtime before continuing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3BYiz5J2lGEv",
    "outputId": "683abf76-c077-46fd-b9dc-fb2e550219b3"
   },
   "source": [
    "!pip install torchvision"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.0+cu101)\n",
      "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.8.0+cu101)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchvision) (3.7.4.3)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLEW1az535Z7"
   },
   "source": [
    "###Import required libraries and classes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_EH_Sd64nE9p"
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFXB_WEC357Z"
   },
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eU20lt1fwBdj"
   },
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnLPogE636pr"
   },
   "source": [
    "### Create the train and test methods"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IC3YcJ2DxTBu"
   },
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print('Train Epoch: {} \\tLoss: {:.6f}'.format(\n",
    "                    epoch,  loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pn7NuNjg37UQ"
   },
   "source": [
    "### Download the datasets, normalize them and train the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DSu-horR2kz8",
    "outputId": "3d7a393e-1488-4289-a7d0-e4019d1518a6"
   },
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=1000, shuffle=True)\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    " \n",
    "for epoch in range(21):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0763, Accuracy: 9753/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 \tLoss: 0.140425\n",
      "\n",
      "Test set: Average loss: 0.0645, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 \tLoss: 0.137073\n",
      "\n",
      "Test set: Average loss: 0.0611, Accuracy: 9812/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 \tLoss: 0.343908\n",
      "\n",
      "Test set: Average loss: 0.0549, Accuracy: 9820/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 \tLoss: 0.117892\n",
      "\n",
      "Test set: Average loss: 0.0526, Accuracy: 9828/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 \tLoss: 0.211196\n",
      "\n",
      "Test set: Average loss: 0.0542, Accuracy: 9834/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 \tLoss: 0.159183\n",
      "\n",
      "Test set: Average loss: 0.0492, Accuracy: 9852/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 \tLoss: 0.137455\n",
      "\n",
      "Test set: Average loss: 0.0465, Accuracy: 9857/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 \tLoss: 0.183048\n",
      "\n",
      "Test set: Average loss: 0.0455, Accuracy: 9868/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 \tLoss: 0.193880\n",
      "\n",
      "Test set: Average loss: 0.0448, Accuracy: 9865/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 \tLoss: 0.028933\n",
      "\n",
      "Test set: Average loss: 0.0445, Accuracy: 9877/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 \tLoss: 0.113090\n",
      "\n",
      "Test set: Average loss: 0.0422, Accuracy: 9871/10000 (99%)\n",
      "\n",
      "Train Epoch: 16 \tLoss: 0.091770\n",
      "\n",
      "Test set: Average loss: 0.0434, Accuracy: 9871/10000 (99%)\n",
      "\n",
      "Train Epoch: 17 \tLoss: 0.086220\n",
      "\n",
      "Test set: Average loss: 0.0401, Accuracy: 9883/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 \tLoss: 0.076834\n",
      "\n",
      "Test set: Average loss: 0.0381, Accuracy: 9884/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 \tLoss: 0.196543\n",
      "\n",
      "Test set: Average loss: 0.0380, Accuracy: 9877/10000 (99%)\n",
      "\n",
      "Train Epoch: 20 \tLoss: 0.082292\n",
      "\n",
      "Test set: Average loss: 0.0405, Accuracy: 9881/10000 (99%)\n",
      "\n",
      "Train Epoch: 0 \tLoss: 2.377307\n",
      "\n",
      "Test set: Average loss: 0.1973, Accuracy: 9403/10000 (94%)\n",
      "\n",
      "Train Epoch: 1 \tLoss: 0.450073\n",
      "\n",
      "Test set: Average loss: 0.1318, Accuracy: 9581/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 \tLoss: 0.514039\n",
      "\n",
      "Test set: Average loss: 0.0985, Accuracy: 9685/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 \tLoss: 0.171799\n",
      "\n",
      "Test set: Average loss: 0.0833, Accuracy: 9730/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 \tLoss: 0.157794\n",
      "\n",
      "Test set: Average loss: 0.0766, Accuracy: 9758/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 \tLoss: 0.156471\n",
      "\n",
      "Test set: Average loss: 0.0638, Accuracy: 9793/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 \tLoss: 0.143752\n",
      "\n",
      "Test set: Average loss: 0.0617, Accuracy: 9811/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 \tLoss: 0.295539\n",
      "\n",
      "Test set: Average loss: 0.0545, Accuracy: 9831/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 \tLoss: 0.105239\n",
      "\n",
      "Test set: Average loss: 0.0528, Accuracy: 9837/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 \tLoss: 0.181777\n",
      "\n",
      "Test set: Average loss: 0.0539, Accuracy: 9832/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 \tLoss: 0.133470\n",
      "\n",
      "Test set: Average loss: 0.0491, Accuracy: 9862/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 \tLoss: 0.131326\n",
      "\n",
      "Test set: Average loss: 0.0466, Accuracy: 9857/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 \tLoss: 0.186313\n",
      "\n",
      "Test set: Average loss: 0.0462, Accuracy: 9866/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 \tLoss: 0.206141\n",
      "\n",
      "Test set: Average loss: 0.0445, Accuracy: 9863/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 \tLoss: 0.034316\n",
      "\n",
      "Test set: Average loss: 0.0451, Accuracy: 9881/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 \tLoss: 0.116052\n",
      "\n",
      "Test set: Average loss: 0.0427, Accuracy: 9876/10000 (99%)\n",
      "\n",
      "Train Epoch: 16 \tLoss: 0.091477\n",
      "\n",
      "Test set: Average loss: 0.0432, Accuracy: 9872/10000 (99%)\n",
      "\n",
      "Train Epoch: 17 \tLoss: 0.073883\n",
      "\n",
      "Test set: Average loss: 0.0400, Accuracy: 9885/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 \tLoss: 0.090850\n",
      "\n",
      "Test set: Average loss: 0.0379, Accuracy: 9882/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 \tLoss: 0.201131\n",
      "\n",
      "Test set: Average loss: 0.0372, Accuracy: 9892/10000 (99%)\n",
      "\n",
      "Train Epoch: 20 \tLoss: 0.093583\n",
      "\n",
      "Test set: Average loss: 0.0403, Accuracy: 9885/10000 (99%)\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxpveW_938Og"
   },
   "source": [
    "### Save the Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tgNoaZ5zwFa2"
   },
   "source": [
    "torch.save(model.state_dict(), 'mnist.pth')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDfDo3HZ38pK"
   },
   "source": [
    "### Load the saved Pytorch model and export it as an ONNX file"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "x_gYxh35zWjr"
   },
   "source": [
    "trained_model = Net()\n",
    "trained_model.load_state_dict(torch.load('mnist.pth'))\n",
    "\n",
    "dummy_input = Variable(torch.randn(1, 1, 28, 28)) \n",
    "torch.onnx.export(trained_model, dummy_input, \"mnist.onnx\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "675zGIJ_5x3O"
   },
   "source": [
    "### Load the ONNX file and import it into Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KjdEU-496qUd"
   },
   "source": [
    "# Load the ONNX file\n",
    "model = onnx.load('mnist.onnx')\n",
    "\n",
    "# Import the ONNX model to Tensorflow\n",
    "tf_rep = prepare(model)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2Pfaw1b5yeE"
   },
   "source": [
    "### Run and test the Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "YHlLIajoxcSn",
    "outputId": "cb2de210-234a-4b2e-9e41-66fff53522bb"
   },
   "source": [
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "print('Image 1:')\n",
    "img = Image.open('/content/img1.png').resize((28, 28)).convert('L')\n",
    "display(img)\n",
    "output = tf_rep.run(np.asarray(img, dtype=np.float32)[np.newaxis, np.newaxis, :, :])\n",
    "print('The digit is classified as ', np.argmax(output))\n",
    "print('------------------------------------------------------------------------------')\n",
    "print('Image 2:')\n",
    "img = Image.open('/content/img2.png').resize((28, 28)).convert('L')\n",
    "display(img)\n",
    "output = tf_rep.run(np.asarray(img, dtype=np.float32)[np.newaxis, np.newaxis, :, :])\n",
    "print('The digit is classified as ', np.argmax(output))"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Image 1:\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAMFGlDQ1BJQ0MgUHJvZmlsZQAAeJyVlwdUk8kWx+crKYSEFoiAlNCbIL1K7x3pYCMkAUKJIRBU7OiigmsXERQVXQFRdC2ArBULFhYBe31RRGVlXSxgQeVNEkCf+/a88+ac+fLLnXvv/Gcy82UGAEV7lkCQjSoBkMPPF0YH+jATk5KZJDFAAA4osJqy2HkC76ioMPCPZegW9IbluqUk1z/7/deizOHmsQFAoiCncvLYOZCPAoBrsgXCfAAIndBuMCdfIOF3kFWFUCAARLKE02WsJeFUGVtLfWKjfSH7AUCmsljCdAAUJPmZBex0mEdBANmaz+HxIe+E7MHOYHEgiyFPysmZDVmRCtk09bs86f+RM3U8J4uVPs6ysUgL2Y+XJ8hmzfs/p+N/l5xs0Vgf+rBSM4RB0ZIxw3mrzZodKmGoHTnBT42IhKwC+RKPI/WX8L0MUVDcqH8/O88XzhlgAIACDssvFDKcS5QhyorzHmVbllAaC/3RCF5+cOwopwpnR4/mRwu4ef4xY5zBDQ4bzbmSnx0xxlVpvIBgyHCloUcLM2ITZDrR8wW8+AjICpA787JiQkf9HxVm+EaM+QhF0RLNhpDfpQkDomU+mHpO3ti4MCs2S6pBHbJXfkZskCwWS+TmJYaNaeNw/fxlGjAOlx83qhmDq8snejS2WJAdNeqPVXGzA6Nl84wdyiuIGYvtzocLTDYP2JNMVkiUTD82JMiPipVpw3EQBnyBH2ACEaypYDbIBLyO/qZ++E3WEgBYQAjSARdYjlrGIhKkLXz4jAGF4E9IXJA3HucjbeWCAmj/Mm6VPS1BmrS1QBqRBZ5BzsE1cQ/cDQ+DTy9YbXFn3GUsjqk41ivRn+hHDCIGEM3GdbCh6mxYhYD3d9u3SMIzQhfhCeEmQUy4C0JhKxeOWaKQPz6yePBUmmX0+yxekfAH5UwQDsQwLmB0dKkwum/MBzeGqh1wH9wd6ofacQauCSxxezgSb9wTjs0BWr9XKBpX8W0uf+xPou/7MY7aFcwVHEZVpI7r9x33+jGL73dzxIGfoT96YiuxI1gbdha7jJ3AmgATO401Y+3YSQmPr4Sn0pUw1lu0VFsWzMMb87Gut+6z/vy33lmjCoTS3xvkc+fmSzaE72zBPCEvPSOf6Q3fyFxmMJ9tNYlpa23jCIDk/S57fbxlSN/bCOPKN1vuGQBcSqAx/ZuNZQDA8WcA0Ie+2QzewO21DoCTnWyRsEBmwyUPAvzXUIQ7QwPoAANgCsdkCxyBG/AC/iAERIJYkARmwlnPADlQ9RywACwFxaAUrAObQQXYAXaDWnAAHAZN4AQ4Cy6Cq6AT3AT34droBS/BABgCwwiCkBAaQkc0EF3ECLFAbBFnxAPxR8KQaCQJSUHSET4iQhYgy5BSZANSgexC6pBfkePIWeQy0oXcRR4jfcgb5BOKoVRUFdVGjdHJqDPqjYaisegMNB3NRQvR5egatBytRvejjehZ9Cp6ExWjL9FBDGDyGAPTwywxZ8wXi8SSsTRMiC3CSrAyrBprwFrgb30dE2P92EeciNNxJm4J12cQHoez8Vx8Eb4ar8Br8Ub8PH4df4wP4F8JNIIWwYLgSggmJBLSCXMIxYQywl7CMcIFuKN6CUNEIpFBNCE6wb2ZRMwkzieuJm4nHiSeIXYRe4iDJBJJg2RBcidFklikfFIxaStpP+k0qZvUS/pAlifrkm3JAeRkMp9cRC4j7yOfIneTn5OH5ZTkjORc5SLlOHLz5NbK7ZFrkbsm1ys3TFGmmFDcKbGUTMpSSjmlgXKB8oDyVl5eXl/eRX6qPE9+iXy5/CH5S/KP5T9SVajmVF/qdKqIuoZaQz1DvUt9S6PRjGletGRaPm0NrY52jvaI9kGBrmClEKzAUVisUKnQqNCt8EpRTtFI0VtxpmKhYpniEcVriv1KckrGSr5KLKVFSpVKx5VuKw0q05VtlCOVc5RXK+9Tvqz8QoWkYqzir8JRWa6yW+WcSg8doxvQfels+jL6HvoFeq8qUdVENVg1U7VU9YBqh+qAmoqavVq82ly1SrWTamIGxjBmBDOyGWsZhxm3GJ8maE/wnsCdsGpCw4TuCe/VJ6p7qXPVS9QPqt9U/6TB1PDXyNJYr9Gk8VAT1zTXnKo5R7NK84Jm/0TViW4T2RNLJh6eeE8L1TLXitaar7Vbq11rUFtHO1BboL1V+5x2vw5Dx0snU2eTzimdPl26rocuT3eT7mndP5hqTG9mNrOceZ45oKelF6Qn0tul16E3rG+iH6dfpH9Q/6EBxcDZIM1gk0GrwYChrmG44QLDesN7RnJGzkYZRluM2ozeG5sYJxivMG4yfmGibhJsUmhSb/LAlGbqaZprWm16w4xo5myWZbbdrNMcNXcwzzCvNL9mgVo4WvAstlt0TSJMcpnEn1Q96bYl1dLbssCy3vKxFcMqzKrIqsnq1WTDycmT109um/zV2sE623qP9X0bFZsQmyKbFps3tua2bNtK2xt2NLsAu8V2zXav7S3sufZV9ncc6A7hDiscWh2+ODo5Ch0bHPucDJ1SnLY53XZWdY5yXu18yYXg4uOy2OWEy0dXR9d818Ouf7lZumW57XN7McVkCnfKnik97vruLPdd7mIPpkeKx04PsaeeJ8uz2vOJl4EXx2uv13NvM+9M7/3er3ysfYQ+x3ze+7r6LvQ944f5BfqV+HX4q/jH+Vf4PwrQD0gPqA8YCHQInB94JogQFBq0Puh2sHYwO7gueCDEKWRhyPlQamhMaEXokzDzMGFYSzgaHhK+MfxBhFEEP6IpEkQGR26MfBhlEpUb9dtU4tSoqZVTn0XbRC+Ibouhx8yK2RczFOsTuzb2fpxpnCiuNV4xfnp8Xfz7BL+EDQnixMmJCxOvJmkm8ZKak0nJ8cl7kwen+U/bPK13usP04um3ZpjMmDvj8kzNmdkzT85SnMWadSSFkJKQsi/lMyuSVc0aTA1O3ZY6wPZlb2G/5HhxNnH6uO7cDdznae5pG9JepLunb0zvy/DMKMvo5/nyKnivM4Myd2S+z4rMqskayU7IPphDzknJOc5X4Wfxz8/WmT13dpfAQlAsEOe65m7OHRCGCvfmIXkz8przVeFRp11kKvpJ9LjAo6Cy4MOc+DlH5irP5c9tn2c+b9W854UBhb/Mx+ez57cu0FuwdMHjhd4Ldy1CFqUual1ssHj54t4lgUtql1KWZi39vci6aEPRu2UJy1qWay9fsrznp8Cf6osVioXFt1e4rdixEl/JW9mxym7V1lVfSzglV0qtS8tKP69mr77ys83P5T+PrElb07HWcW3VOuI6/rpb6z3X125Q3lC4oWdj+MbGTcxNJZvebZ61+XKZfdmOLZQtoi3i8rDy5q2GW9dt/VyRUXGz0qfy4Datbau2vd/O2d5d5VXVsEN7R+mOTzt5O+/sCtzVWG1cXbabuLtg97M98XvafnH+pW6v5t7SvV9q+DXi2uja83VOdXX7tPatrUfrRfV9+6fv7zzgd6C5wbJh10HGwdJD4JDo0B+/pvx663Do4dYjzkcajhod3XaMfqykEWmc1zjQlNEkbk5q7joecry1xa3l2G9Wv9Wc0DtReVLt5NpTlFPLT42cLjw9eEZwpv9s+tme1lmt988lnrtxfur5jguhFy5dDLh4rs277fQl90snLrtePn7F+UrTVcerje0O7cd+d/j9WIdjR+M1p2vNnS6dLV1Tuk51e3afve53/eKN4BtXb0bc7LoVd+vO7em3xXc4d17czb77+l7BveH7Sx4QHpQ8VHpY9kjrUfW/zP51UOwoPvnY73H7k5gn93vYPS+f5j393Lv8Ge1Z2XPd53UvbF+c6Avo6/xj2h+9LwUvh/uL/1T+c9sr01dH//L6q30gcaD3tfD1yJvVbzXe1ryzf9c6GDX4aChnaPh9yQeND7UfnT+2fUr49Hx4zmfS5/IvZl9avoZ+fTCSMzIiYAlZ0qMABiualgbAmxoAaEnw7ADvcRQF2f1LWhDZnVFK4J9YdkeTFnhyqfECIG4JAGHwjFIFqxFkKvyUHL9jvQBqZzdeR0temp2tLBcV3mIIH0ZG3moDQGoB4ItwZGR4+8jIlz1Q7F0AzuTK7n2SQoRn/J1mEupop4Afy78B56FrHGvPucAAAAFgSURBVHicYzzHw8iAHfz/wsKnjEOOgeEuE04pBgYG8iVZULn/vr05x+bGhk3y993VZ+58EHwfA/PAnf9Q8O/7uWItXg4FJUbv5xCROwjJ1zUaXAyMjieXMupdhUrCjf23Z+5zBlbzLoN3DP//o9v5++gXAQWTTKOv9//D3QCXZMtS0lSR5Gb4+RyLTkZNFVaGPz8Z3l5hYGFBl2RgYP37eM0X5g83+J1VMCR/3z879xjL739/LFMwdH7c3vRZ0F5y01uG57vluFAD4V6PoOjEK982KrFIcMvMuPf9529EIDzOZJfI//Bjlxa77YQEadGw+UuOwSVf5gkYLnp4Y5KWXOLlv6+3ZSjxSHfBJP918Qs0bG4xZ9Ve8ub/////PywvmfkBJvnHkYFZUlhII2DD7/9IABK2jHZv37Kq2lhYiKLGLuMdZQYGhp8XbvFZC6Mnw7uIKMMEd2iV+j7dxp0dAAPb5ugh/EDeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FDD394C8C50>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "The digit is classified as  2\n",
      "------------------------------------------------------------------------------\n",
      "Image 2:\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB3klEQVR4nH3TvWsUQRQA8Pd2ZvfW291bch/JLUlMI4YrjB8oikUO0wiCWAkRtJcIgpDC1to/QUhhYyFqIYiK6U6IhUUinIrmQDxByUWW5D73dt6zyO7tHqivmcf8YJh57w0S/Du0/9hfETFKZLwBAMAHq2IJnMZ+OxBZA1n1w05z/0jZ0kaInQcPB97iuUx7+0WL93runWsWR4hqY+2z+vLOQBh2Fch81tMYAICIiHevZIWGgLpd8KZnqls7PUVEJAEA1YfNAUhnIme7J6uTjlWE1IWGnzog5u4uGaYQpowkxsH7HmbKFdugQ0ZCEVJzKML6Dfeoc+F0wRWJEhH7l3VNCISMWfTO1HYpDiAiDtdnAYQ96c0WpF46u51G4vb9SmFu+VXje+28pRlXf3EKiVobj+qtgDn8eL0opx8POI08DJiZiOnbTcte9ceQiOPkbVmcis496CePXofoCPWTx/qpNEQGBOg1V3YgJ9Lo141S3sFu4K89+Rrk77kJotpc+e1cuiWev2m0/FBWl3QeVYi4cQzExInqQsmQmji+NV6E/tOKgTJj6qiZCy8DTiOR/3rxsJvRzan5i+v9UW0xGmq19+NZbX/q9nw2l3QlRgTuDljLiXQ/MfkO8egm8QfuAiaY1DMQLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FDD3C234D10>"
      ]
     },
     "metadata": {
      "tags": []
     }
    },
    {
     "output_type": "stream",
     "text": [
      "The digit is classified as  5\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aFZScgO-MI2",
    "outputId": "7107da8c-197a-4662-e8fa-5793220b135a"
   },
   "source": [
    "tf_rep.export_graph('mnist.pb')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as gen_tensor_dict while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist.pb/assets\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist.pb/assets\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NOw8u6fNlFdo"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
